{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c48075ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d936f847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('voice.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f16a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adddbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "data['label'] = label_encoder.fit_transform(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d89587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'female', 1: 'male'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6cdf39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx  label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000      1  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632      1  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512      1  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119      1  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274      1  \n",
       "...        ...       ...       ...       ...       ...       ...    ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929      0  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897      0  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759      0  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002      0  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000      0  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71952384",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitiing and scaling\n",
    "y = data['label'].copy()\n",
    "X = data.drop('label', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d74cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "095a882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e058a01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 20)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modeling and training\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e26351d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X.shape[1],))\n",
    "\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54876755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 20)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1344      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5569 (21.75 KB)\n",
      "Trainable params: 5569 (21.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dedccd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 3s 15ms/step - loss: 0.3878 - accuracy: 0.8641 - auc: 0.9456 - val_loss: 0.1761 - val_accuracy: 0.9775 - val_auc: 0.9969\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9605 - auc: 0.9918 - val_loss: 0.0765 - val_accuracy: 0.9865 - val_auc: 0.9977\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9707 - auc: 0.9947 - val_loss: 0.0663 - val_accuracy: 0.9797 - val_auc: 0.9972\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9741 - auc: 0.9962 - val_loss: 0.0615 - val_accuracy: 0.9797 - val_auc: 0.9975\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0696 - accuracy: 0.9757 - auc: 0.9969 - val_loss: 0.0590 - val_accuracy: 0.9820 - val_auc: 0.9975\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9780 - auc: 0.9972 - val_loss: 0.0588 - val_accuracy: 0.9842 - val_auc: 0.9977\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0602 - accuracy: 0.9797 - auc: 0.9973 - val_loss: 0.0535 - val_accuracy: 0.9842 - val_auc: 0.9980\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0573 - accuracy: 0.9786 - auc: 0.9978 - val_loss: 0.0711 - val_accuracy: 0.9797 - val_auc: 0.9962\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0527 - accuracy: 0.9808 - auc: 0.9983 - val_loss: 0.0444 - val_accuracy: 0.9865 - val_auc: 0.9984\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9825 - auc: 0.9984 - val_loss: 0.0494 - val_accuracy: 0.9842 - val_auc: 0.9980\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0491 - accuracy: 0.9808 - auc: 0.9984 - val_loss: 0.0618 - val_accuracy: 0.9842 - val_auc: 0.9969\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.0459 - accuracy: 0.9842 - auc: 0.9987 - val_loss: 0.0571 - val_accuracy: 0.9842 - val_auc: 0.9978\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "         tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a846f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9811 - auc: 0.9972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06368658691644669, 0.9810725450515747, 0.9972334504127502]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bb33fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using 2d CNN\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, dtype=np.float32, maxlen=25, padding='post')\n",
    "X = X.reshape(-1, 5, 5)\n",
    "X = np.expand_dims(X, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd196223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3168, 5, 5, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f157d855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1200 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(np.squeeze(X[i]))\n",
    "    plt.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4acead7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59072ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(X.shape[1], X.shape[2], X.shape[3]))\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, 2, activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(32, 1, activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84f3df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 5, 5, 1)]         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 4, 4, 16)          80        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 2, 2, 16)          0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 2, 2, 32)          544       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 1, 1, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2801 (10.94 KB)\n",
      "Trainable params: 2801 (10.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff115a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "56/56 [==============================] - 3s 15ms/step - loss: 0.6624 - accuracy: 0.6187 - auc: 0.6967 - val_loss: 0.6185 - val_accuracy: 0.6914 - val_auc: 0.7891\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7456 - auc: 0.8491 - val_loss: 0.5012 - val_accuracy: 0.7725 - val_auc: 0.8699\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8488 - auc: 0.9179 - val_loss: 0.3642 - val_accuracy: 0.8581 - val_auc: 0.9424\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.3060 - accuracy: 0.8962 - auc: 0.9554 - val_loss: 0.2808 - val_accuracy: 0.8761 - val_auc: 0.9725\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2461 - accuracy: 0.9120 - auc: 0.9676 - val_loss: 0.2248 - val_accuracy: 0.9167 - val_auc: 0.9767\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.2124 - accuracy: 0.9216 - auc: 0.9756 - val_loss: 0.1906 - val_accuracy: 0.9167 - val_auc: 0.9843\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1932 - accuracy: 0.9278 - auc: 0.9788 - val_loss: 0.1737 - val_accuracy: 0.9347 - val_auc: 0.9862\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.9323 - auc: 0.9808 - val_loss: 0.1592 - val_accuracy: 0.9414 - val_auc: 0.9878\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1657 - accuracy: 0.9346 - auc: 0.9849 - val_loss: 0.1476 - val_accuracy: 0.9369 - val_auc: 0.9901\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1606 - accuracy: 0.9397 - auc: 0.9849 - val_loss: 0.1643 - val_accuracy: 0.9392 - val_auc: 0.9891\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9419 - auc: 0.9874 - val_loss: 0.1398 - val_accuracy: 0.9459 - val_auc: 0.9920\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9453 - auc: 0.9868 - val_loss: 0.1346 - val_accuracy: 0.9505 - val_auc: 0.9909\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1376 - accuracy: 0.9515 - auc: 0.9885 - val_loss: 0.1398 - val_accuracy: 0.9482 - val_auc: 0.9912\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1325 - accuracy: 0.9504 - auc: 0.9898 - val_loss: 0.1287 - val_accuracy: 0.9482 - val_auc: 0.9918\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1261 - accuracy: 0.9532 - auc: 0.9910 - val_loss: 0.1230 - val_accuracy: 0.9505 - val_auc: 0.9923\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1355 - accuracy: 0.9459 - auc: 0.9888 - val_loss: 0.1203 - val_accuracy: 0.9527 - val_auc: 0.9925\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1204 - accuracy: 0.9566 - auc: 0.9915 - val_loss: 0.1149 - val_accuracy: 0.9550 - val_auc: 0.9932\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1135 - accuracy: 0.9560 - auc: 0.9922 - val_loss: 0.1115 - val_accuracy: 0.9527 - val_auc: 0.9936\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1120 - accuracy: 0.9549 - auc: 0.9930 - val_loss: 0.1126 - val_accuracy: 0.9550 - val_auc: 0.9932\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9605 - auc: 0.9942 - val_loss: 0.1101 - val_accuracy: 0.9527 - val_auc: 0.9933\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.1067 - accuracy: 0.9583 - auc: 0.9936 - val_loss: 0.1504 - val_accuracy: 0.9369 - val_auc: 0.9920\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 0.1073 - accuracy: 0.9554 - auc: 0.9931 - val_loss: 0.1083 - val_accuracy: 0.9550 - val_auc: 0.9936\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9622 - auc: 0.9948 - val_loss: 0.1162 - val_accuracy: 0.9505 - val_auc: 0.9942\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9633 - auc: 0.9948 - val_loss: 0.1044 - val_accuracy: 0.9617 - val_auc: 0.9936\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0925 - accuracy: 0.9633 - auc: 0.9951 - val_loss: 0.1100 - val_accuracy: 0.9572 - val_auc: 0.9933\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0886 - accuracy: 0.9616 - auc: 0.9957 - val_loss: 0.1013 - val_accuracy: 0.9595 - val_auc: 0.9940\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0903 - accuracy: 0.9656 - auc: 0.9952 - val_loss: 0.1001 - val_accuracy: 0.9617 - val_auc: 0.9942\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9690 - auc: 0.9961 - val_loss: 0.1079 - val_accuracy: 0.9550 - val_auc: 0.9937\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9690 - auc: 0.9960 - val_loss: 0.1012 - val_accuracy: 0.9595 - val_auc: 0.9944\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9707 - auc: 0.9959 - val_loss: 0.1188 - val_accuracy: 0.9482 - val_auc: 0.9943\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.AUC(name='auc')\n",
    "    ]\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea897ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9558 - auc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10968353599309921, 0.9558359384536743, 0.9926002621650696]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
